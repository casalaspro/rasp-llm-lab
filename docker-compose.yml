version: "3.9"

services:
  llm-api:
    build: ./llm-api
    container_name: llm-api
    ports:
      - "8080:8080"